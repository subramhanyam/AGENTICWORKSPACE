{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88dc84d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4db2ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://langchain-ai.github.io/langgraph/guides/\",\n",
    "    \"https://langchain-ai.github.io/langgraph/agents/overview/\",\n",
    "    \"https://langchain-ai.github.io/langgraph/agents/run_agents/\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f999114a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/guides/', 'title': 'Guides', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content=\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGuides\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\n            \\n            \\nOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!\\n\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              Guides\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Get started\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Additional resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Guides\\n          \\n\\n\\n\\n\\n\\n    Agent development\\n    \\n  \\n\\n\\n\\n\\n\\n            Agent development\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Run an agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph APIs\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph APIs\\n          \\n\\n\\n\\n\\n    Graph API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Functional API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Runtime\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Core capabilities\\n    \\n  \\n\\n\\n\\n\\n\\n            Core capabilities\\n          \\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Persistence\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Durable execution\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Context\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Models\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Subgraphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    MCP\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tracing\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Platform-only capabilities\\n    \\n  \\n\\n\\n\\n\\n\\n            Platform-only capabilities\\n          \\n\\n\\n\\n\\n    LangGraph Platform\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Authentication & access control\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Assistants\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Double-texting\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Webhooks\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Cron jobs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Server customization\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Data management\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Additional resources\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Agent development\\n    \\n\\n\\n\\n\\n\\n      LangGraph APIs\\n    \\n\\n\\n\\n\\n\\n      Core capabilities\\n    \\n\\n\\n\\n\\n\\n      Platform-only capabilities\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGuides¶\\nThe pages in this section provide a conceptual overview and how-tos for the following topics:\\nAgent development¶\\n\\nOverview: Use prebuilt components to build an agent.\\nRun an agent: Run an agent by providing input, interpreting output, enabling streaming, and controlling execution limits.\\n\\nLangGraph APIs¶\\n\\nGraph API: Use the Graph API to define workflows using a graph paradigm.\\nFunctional API: Use Functional API to build workflows using a functional paradigm without thinking about the graph structure.\\nRuntime: Pregel implements LangGraph's runtime, managing the execution of LangGraph applications.\\n\\nCore capabilities¶\\nThese capabilities are available in both LangGraph OSS and the LangGraph Platform.\\n\\nStreaming: Stream outputs from a LangGraph graph.\\nPersistence: Persist the state of a LangGraph graph.\\nDurable execution: Save progress at key points in the graph execution.\\nMemory: Remember information about previous interactions.\\nContext: Pass outside data to a LangGraph graph to provide context for the graph execution.\\nModels: Integrate various LLMs into your LangGraph application.\\nTools: Interface directly with external systems.\\nHuman-in-the-loop: Pause a graph and wait for human input at any point in a workflow.\\nTime travel: Travel back in time to a specific point in the execution of a LangGraph graph.\\nSubgraphs: Build modular graphs.\\nMulti-agent: Break down a complex workflow into multiple agents.\\nMCP: Use MCP servers in a LangGraph graph.\\nEvaluation: Use LangSmith to evaluate your graph's performance.\\n\\nPlatform-only capabilities¶\\nThese capabilities are only available in LangGraph Platform.\\n\\nAuthentication and access control: Authenticate and authorize users to access a LangGraph graph.\\nAssistants: Build assistants that can be used to interact with a LangGraph graph.\\nDouble-texting: Handle double-texting (consecutive messages before a first response is returned) in a LangGraph graph.\\nWebhooks: Send webhooks to a LangGraph graph.\\nCron jobs: Schedule jobs to run at a specific time.\\nServer customization: Customize the server that runs a LangGraph graph.\\nData management: Manage data in a LangGraph graph.\\nDeployment: Deploy a LangGraph graph to a server.\\n\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                Agent architectures\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                Overview\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Copyright © 2025 LangChain, Inc | Consent Preferences\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\")],\n",
       " [Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/agents/overview/', 'title': 'Overview', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content=\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\n            \\n            \\nOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!\\n\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              Overview\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Get started\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Additional resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Guides\\n          \\n\\n\\n\\n\\n\\n    Agent development\\n    \\n  \\n\\n\\n\\n\\n\\n            Agent development\\n          \\n\\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      What is an agent?\\n    \\n\\n\\n\\n\\n\\n      Key features\\n    \\n\\n\\n\\n\\n\\n      High-level building blocks\\n    \\n\\n\\n\\n\\n\\n      Package ecosystem\\n    \\n\\n\\n\\n\\n\\n      Visualize an agent graph\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n    Run an agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph APIs\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph APIs\\n          \\n\\n\\n\\n\\n    Graph API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Functional API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Runtime\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Core capabilities\\n    \\n  \\n\\n\\n\\n\\n\\n            Core capabilities\\n          \\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Persistence\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Durable execution\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Context\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Models\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Subgraphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    MCP\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tracing\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Platform-only capabilities\\n    \\n  \\n\\n\\n\\n\\n\\n            Platform-only capabilities\\n          \\n\\n\\n\\n\\n    LangGraph Platform\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Authentication & access control\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Assistants\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Double-texting\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Webhooks\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Cron jobs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Server customization\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Data management\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Additional resources\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      What is an agent?\\n    \\n\\n\\n\\n\\n\\n      Key features\\n    \\n\\n\\n\\n\\n\\n      High-level building blocks\\n    \\n\\n\\n\\n\\n\\n      Package ecosystem\\n    \\n\\n\\n\\n\\n\\n      Visualize an agent graph\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nagent\\n\\n\\n\\n\\nAgent development using prebuilt components¶\\nLangGraph provides both low-level primitives and high-level prebuilt components for building agent-based applications. This section focuses on the prebuilt, ready-to-use components designed to help you construct agentic systems quickly and reliably—without the need to implement orchestration, memory, or human feedback handling from scratch.\\nWhat is an agent?¶\\nAn agent consists of three components: a large language model (LLM), a set of tools it can use, and a prompt that provides instructions.\\nThe LLM operates in a loop. In each iteration, it selects a tool to invoke, provides input, receives the result (an observation), and uses that observation to inform the next action. The loop continues until a stopping condition is met — typically when the agent has gathered enough information to respond to the user.\\n\\n\\nAgent loop: the LLM selects tools and uses their outputs to fulfill a user request.\\n\\nKey features¶\\nLangGraph includes several capabilities essential for building robust, production-ready agentic systems:\\n\\nMemory integration: Native support for short-term (session-based) and long-term (persistent across sessions) memory, enabling stateful behaviors in chatbots and assistants.\\nHuman-in-the-loop control: Execution can pause indefinitely to await human feedback—unlike websocket-based solutions limited to real-time interaction. This enables asynchronous approval, correction, or intervention at any point in the workflow.\\nStreaming support: Real-time streaming of agent state, model tokens, tool outputs, or combined streams.\\nDeployment tooling: Includes infrastructure-free deployment tools. LangGraph Platform supports testing, debugging, and deployment.\\nStudio: A visual IDE for inspecting and debugging workflows.\\nSupports multiple deployment options for production.\\n\\n\\n\\nHigh-level building blocks¶\\nLangGraph comes with a set of prebuilt components that implement common agent behaviors and workflows. These abstractions are built on top of the LangGraph framework, offering a faster path to production while remaining flexible for advanced customization.\\nUsing LangGraph for agent development allows you to focus on your application's logic and behavior, instead of building and maintaining the supporting infrastructure for state, memory, and human feedback.\\nPackage ecosystem¶\\nThe high-level components are organized into several packages, each with a specific focus.\\n\\n\\n\\nPackage\\nDescription\\nInstallation\\n\\n\\n\\n\\nlanggraph-prebuilt (part of langgraph)\\nPrebuilt components to create agents\\npip install -U langgraph langchain\\n\\n\\nlanggraph-supervisor\\nTools for building supervisor agents\\npip install -U langgraph-supervisor\\n\\n\\nlanggraph-swarm\\nTools for building a swarm multi-agent system\\npip install -U langgraph-swarm\\n\\n\\nlangchain-mcp-adapters\\nInterfaces to MCP servers for tool and resource integration\\npip install -U langchain-mcp-adapters\\n\\n\\nlangmem\\nAgent memory management: short-term and long-term\\npip install -U langmem\\n\\n\\nagentevals\\nUtilities to evaluate agent performance\\npip install -U agentevals\\n\\n\\n\\nVisualize an agent graph¶\\nUse the following tool to visualize the graph generated by\\ncreate_react_agent\\nand to view an outline of the corresponding code.\\nIt allows you to explore the infrastructure of the agent as defined by the presence of:\\n\\ntools: A list of tools (functions, APIs, or other callable objects) that the agent can use to perform tasks.\\npre_model_hook: A function that is called before the model is invoked. It can be used to condense messages or perform other preprocessing tasks.\\npost_model_hook: A function that is called after the model is invoked. It can be used to implement guardrails, human-in-the-loop flows, or other postprocessing tasks.\\nresponse_format: A data structure used to constrain the type of the final output, e.g., a pydantic BaseModel.\\n\\n\\n\\n\\nFeatures\\n tools\\n pre_model_hook\\n post_model_hook\\n response_format\\n\\n\\n\\nGraph\\n\\n\\n\\nThe following code snippet shows how to create the above agent (and underlying graph) with\\ncreate_react_agent:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                Guides\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                Run an agent\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Copyright © 2025 LangChain, Inc | Consent Preferences\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\")],\n",
       " [Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/agents/run_agents/', 'title': 'Run an agent', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRun an agent\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\n            \\n            \\nOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!\\n\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              Run an agent\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Get started\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Additional resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Guides\\n          \\n\\n\\n\\n\\n\\n    Agent development\\n    \\n  \\n\\n\\n\\n\\n\\n            Agent development\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Run an agent\\n    \\n  \\n\\n\\n\\n\\n    Run an agent\\n    \\n  \\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Basic usage\\n    \\n\\n\\n\\n\\n\\n      Inputs and outputs\\n    \\n\\n\\n\\n\\n\\n      Input format\\n    \\n\\n\\n\\n\\n\\n      Output format\\n    \\n\\n\\n\\n\\n\\n      Streaming output\\n    \\n\\n\\n\\n\\n\\n      Max iterations\\n    \\n\\n\\n\\n\\n\\n      Additional Resources\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph APIs\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph APIs\\n          \\n\\n\\n\\n\\n    Graph API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Functional API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Runtime\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Core capabilities\\n    \\n  \\n\\n\\n\\n\\n\\n            Core capabilities\\n          \\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Persistence\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Durable execution\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Context\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Models\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Subgraphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    MCP\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tracing\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Platform-only capabilities\\n    \\n  \\n\\n\\n\\n\\n\\n            Platform-only capabilities\\n          \\n\\n\\n\\n\\n    LangGraph Platform\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Authentication & access control\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Assistants\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Double-texting\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Webhooks\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Cron jobs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Server customization\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Data management\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Additional resources\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Basic usage\\n    \\n\\n\\n\\n\\n\\n      Inputs and outputs\\n    \\n\\n\\n\\n\\n\\n      Input format\\n    \\n\\n\\n\\n\\n\\n      Output format\\n    \\n\\n\\n\\n\\n\\n      Streaming output\\n    \\n\\n\\n\\n\\n\\n      Max iterations\\n    \\n\\n\\n\\n\\n\\n      Additional Resources\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nagent\\n\\n\\n\\n\\nRunning agents¶\\nAgents support both synchronous and asynchronous execution using either .invoke() / await .ainvoke() for full responses, or .stream() / .astream() for incremental streaming output. This section explains how to provide input, interpret output, enable streaming, and control execution limits.\\nBasic usage¶\\nAgents can be executed in two primary modes:\\n\\nSynchronous using .invoke() or .stream()\\nAsynchronous using await .ainvoke() or async for with .astream()\\n\\nSync invocationAsync invocation\\n\\n\\nfrom langgraph.prebuilt import create_react_agent\\n\\nagent = create_react_agent(...)\\n\\nresponse = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]})\\n\\n\\n\\nfrom langgraph.prebuilt import create_react_agent\\n\\nagent = create_react_agent(...)\\nresponse = await agent.ainvoke({\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]})\\n\\n\\n\\n\\nInputs and outputs¶\\nAgents use a language model that expects a list of messages as an input. Therefore, agent inputs and outputs are stored as a list of messages under the messages key in the agent state.\\nInput format¶\\nAgent input must be a dictionary with a messages key. Supported formats are:\\n\\n\\n\\nFormat\\nExample\\n\\n\\n\\n\\nString\\n{\"messages\": \"Hello\"}  — Interpreted as a HumanMessage\\n\\n\\nMessage dictionary\\n{\"messages\": {\"role\": \"user\", \"content\": \"Hello\"}}\\n\\n\\nList of messages\\n{\"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}]}\\n\\n\\nWith custom state\\n{\"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}], \"user_name\": \"Alice\"} — If using a custom state_schema\\n\\n\\n\\nMessages are automatically converted into LangChain\\'s internal message format. You can read\\nmore about LangChain messages in the LangChain documentation.\\n\\nUsing custom agent state\\nYou can provide additional fields defined in your agent’s state schema directly in the input dictionary. This allows dynamic behavior based on runtime data or prior tool outputs.\\nSee the context guide for full details.\\n\\n\\nNote\\nA string input for messages is converted to a HumanMessage. This behavior differs from the prompt parameter in create_react_agent, which is interpreted as a SystemMessage when passed as a string.\\n\\nOutput format¶\\nAgent output is a dictionary containing:\\n\\nmessages: A list of all messages exchanged during execution (user input, assistant replies, tool invocations).\\nOptionally, structured_response if structured output is configured.\\nIf using a custom state_schema, additional keys corresponding to your defined fields may also be present in the output. These can hold updated state values from tool execution or prompt logic.\\n\\nSee the context guide for more details on working with custom state schemas and accessing context.\\nStreaming output¶\\nAgents support streaming responses for more responsive applications. This includes:\\n\\nProgress updates after each step\\nLLM tokens as they\\'re generated\\nCustom tool messages during execution\\n\\nStreaming is available in both sync and async modes:\\nSync streamingAsync streaming\\n\\n\\nfor chunk in agent.stream(\\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]},\\n    stream_mode=\"updates\"\\n):\\n    print(chunk)\\n\\n\\n\\nasync for chunk in agent.astream(\\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]},\\n    stream_mode=\"updates\"\\n):\\n    print(chunk)\\n\\n\\n\\n\\n\\nTip\\nFor full details, see the streaming guide.\\n\\nMax iterations¶\\nTo control agent execution and avoid infinite loops, set a recursion limit. This defines the maximum number of steps the agent can take before raising a GraphRecursionError. You can configure recursion_limit at runtime or when defining agent via .with_config():\\nRuntime.with_config()\\n\\n\\nfrom langgraph.errors import GraphRecursionError\\nfrom langgraph.prebuilt import create_react_agent\\n\\nmax_iterations = 3\\nrecursion_limit = 2 * max_iterations + 1\\nagent = create_react_agent(\\n    model=\"anthropic:claude-3-5-haiku-latest\",\\n    tools=[get_weather]\\n)\\n\\ntry:\\n    response = agent.invoke(\\n        {\"messages\": [{\"role\": \"user\", \"content\": \"what\\'s the weather in sf\"}]},\\n        {\"recursion_limit\": recursion_limit},\\n    )\\nexcept GraphRecursionError:\\n    print(\"Agent stopped due to max iterations.\")\\n\\n\\n\\nfrom langgraph.errors import GraphRecursionError\\nfrom langgraph.prebuilt import create_react_agent\\n\\nmax_iterations = 3\\nrecursion_limit = 2 * max_iterations + 1\\nagent = create_react_agent(\\n    model=\"anthropic:claude-3-5-haiku-latest\",\\n    tools=[get_weather]\\n)\\nagent_with_recursion_limit = agent.with_config(recursion_limit=recursion_limit)\\n\\ntry:\\n    response = agent_with_recursion_limit.invoke(\\n        {\"messages\": [{\"role\": \"user\", \"content\": \"what\\'s the weather in sf\"}]},\\n    )\\nexcept GraphRecursionError:\\n    print(\"Agent stopped due to max iterations.\")\\n\\n\\n\\n\\nAdditional Resources¶\\n\\nAsync programming in LangChain\\n\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                Overview\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                Overview\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Copyright © 2025 LangChain, Inc | Consent Preferences\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "679d93cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/guides/', 'title': 'Guides', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content=\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGuides\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\n            \\n            \\nOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!\\n\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              Guides\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Get started\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Additional resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Guides\\n          \\n\\n\\n\\n\\n\\n    Agent development\\n    \\n  \\n\\n\\n\\n\\n\\n            Agent development\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Run an agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph APIs\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph APIs\\n          \\n\\n\\n\\n\\n    Graph API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Functional API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Runtime\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Core capabilities\\n    \\n  \\n\\n\\n\\n\\n\\n            Core capabilities\\n          \\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Persistence\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Durable execution\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Context\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Models\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Subgraphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    MCP\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tracing\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Platform-only capabilities\\n    \\n  \\n\\n\\n\\n\\n\\n            Platform-only capabilities\\n          \\n\\n\\n\\n\\n    LangGraph Platform\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Authentication & access control\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Assistants\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Double-texting\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Webhooks\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Cron jobs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Server customization\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Data management\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Additional resources\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Agent development\\n    \\n\\n\\n\\n\\n\\n      LangGraph APIs\\n    \\n\\n\\n\\n\\n\\n      Core capabilities\\n    \\n\\n\\n\\n\\n\\n      Platform-only capabilities\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGuides¶\\nThe pages in this section provide a conceptual overview and how-tos for the following topics:\\nAgent development¶\\n\\nOverview: Use prebuilt components to build an agent.\\nRun an agent: Run an agent by providing input, interpreting output, enabling streaming, and controlling execution limits.\\n\\nLangGraph APIs¶\\n\\nGraph API: Use the Graph API to define workflows using a graph paradigm.\\nFunctional API: Use Functional API to build workflows using a functional paradigm without thinking about the graph structure.\\nRuntime: Pregel implements LangGraph's runtime, managing the execution of LangGraph applications.\\n\\nCore capabilities¶\\nThese capabilities are available in both LangGraph OSS and the LangGraph Platform.\\n\\nStreaming: Stream outputs from a LangGraph graph.\\nPersistence: Persist the state of a LangGraph graph.\\nDurable execution: Save progress at key points in the graph execution.\\nMemory: Remember information about previous interactions.\\nContext: Pass outside data to a LangGraph graph to provide context for the graph execution.\\nModels: Integrate various LLMs into your LangGraph application.\\nTools: Interface directly with external systems.\\nHuman-in-the-loop: Pause a graph and wait for human input at any point in a workflow.\\nTime travel: Travel back in time to a specific point in the execution of a LangGraph graph.\\nSubgraphs: Build modular graphs.\\nMulti-agent: Break down a complex workflow into multiple agents.\\nMCP: Use MCP servers in a LangGraph graph.\\nEvaluation: Use LangSmith to evaluate your graph's performance.\\n\\nPlatform-only capabilities¶\\nThese capabilities are only available in LangGraph Platform.\\n\\nAuthentication and access control: Authenticate and authorize users to access a LangGraph graph.\\nAssistants: Build assistants that can be used to interact with a LangGraph graph.\\nDouble-texting: Handle double-texting (consecutive messages before a first response is returned) in a LangGraph graph.\\nWebhooks: Send webhooks to a LangGraph graph.\\nCron jobs: Schedule jobs to run at a specific time.\\nServer customization: Customize the server that runs a LangGraph graph.\\nData management: Manage data in a LangGraph graph.\\nDeployment: Deploy a LangGraph graph to a server.\\n\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                Agent architectures\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                Overview\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Copyright © 2025 LangChain, Inc | Consent Preferences\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\"),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/agents/overview/', 'title': 'Overview', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content=\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\n            \\n            \\nOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!\\n\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              Overview\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Get started\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Additional resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Guides\\n          \\n\\n\\n\\n\\n\\n    Agent development\\n    \\n  \\n\\n\\n\\n\\n\\n            Agent development\\n          \\n\\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      What is an agent?\\n    \\n\\n\\n\\n\\n\\n      Key features\\n    \\n\\n\\n\\n\\n\\n      High-level building blocks\\n    \\n\\n\\n\\n\\n\\n      Package ecosystem\\n    \\n\\n\\n\\n\\n\\n      Visualize an agent graph\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n    Run an agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph APIs\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph APIs\\n          \\n\\n\\n\\n\\n    Graph API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Functional API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Runtime\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Core capabilities\\n    \\n  \\n\\n\\n\\n\\n\\n            Core capabilities\\n          \\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Persistence\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Durable execution\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Context\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Models\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Subgraphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    MCP\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tracing\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Platform-only capabilities\\n    \\n  \\n\\n\\n\\n\\n\\n            Platform-only capabilities\\n          \\n\\n\\n\\n\\n    LangGraph Platform\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Authentication & access control\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Assistants\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Double-texting\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Webhooks\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Cron jobs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Server customization\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Data management\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Additional resources\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      What is an agent?\\n    \\n\\n\\n\\n\\n\\n      Key features\\n    \\n\\n\\n\\n\\n\\n      High-level building blocks\\n    \\n\\n\\n\\n\\n\\n      Package ecosystem\\n    \\n\\n\\n\\n\\n\\n      Visualize an agent graph\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nagent\\n\\n\\n\\n\\nAgent development using prebuilt components¶\\nLangGraph provides both low-level primitives and high-level prebuilt components for building agent-based applications. This section focuses on the prebuilt, ready-to-use components designed to help you construct agentic systems quickly and reliably—without the need to implement orchestration, memory, or human feedback handling from scratch.\\nWhat is an agent?¶\\nAn agent consists of three components: a large language model (LLM), a set of tools it can use, and a prompt that provides instructions.\\nThe LLM operates in a loop. In each iteration, it selects a tool to invoke, provides input, receives the result (an observation), and uses that observation to inform the next action. The loop continues until a stopping condition is met — typically when the agent has gathered enough information to respond to the user.\\n\\n\\nAgent loop: the LLM selects tools and uses their outputs to fulfill a user request.\\n\\nKey features¶\\nLangGraph includes several capabilities essential for building robust, production-ready agentic systems:\\n\\nMemory integration: Native support for short-term (session-based) and long-term (persistent across sessions) memory, enabling stateful behaviors in chatbots and assistants.\\nHuman-in-the-loop control: Execution can pause indefinitely to await human feedback—unlike websocket-based solutions limited to real-time interaction. This enables asynchronous approval, correction, or intervention at any point in the workflow.\\nStreaming support: Real-time streaming of agent state, model tokens, tool outputs, or combined streams.\\nDeployment tooling: Includes infrastructure-free deployment tools. LangGraph Platform supports testing, debugging, and deployment.\\nStudio: A visual IDE for inspecting and debugging workflows.\\nSupports multiple deployment options for production.\\n\\n\\n\\nHigh-level building blocks¶\\nLangGraph comes with a set of prebuilt components that implement common agent behaviors and workflows. These abstractions are built on top of the LangGraph framework, offering a faster path to production while remaining flexible for advanced customization.\\nUsing LangGraph for agent development allows you to focus on your application's logic and behavior, instead of building and maintaining the supporting infrastructure for state, memory, and human feedback.\\nPackage ecosystem¶\\nThe high-level components are organized into several packages, each with a specific focus.\\n\\n\\n\\nPackage\\nDescription\\nInstallation\\n\\n\\n\\n\\nlanggraph-prebuilt (part of langgraph)\\nPrebuilt components to create agents\\npip install -U langgraph langchain\\n\\n\\nlanggraph-supervisor\\nTools for building supervisor agents\\npip install -U langgraph-supervisor\\n\\n\\nlanggraph-swarm\\nTools for building a swarm multi-agent system\\npip install -U langgraph-swarm\\n\\n\\nlangchain-mcp-adapters\\nInterfaces to MCP servers for tool and resource integration\\npip install -U langchain-mcp-adapters\\n\\n\\nlangmem\\nAgent memory management: short-term and long-term\\npip install -U langmem\\n\\n\\nagentevals\\nUtilities to evaluate agent performance\\npip install -U agentevals\\n\\n\\n\\nVisualize an agent graph¶\\nUse the following tool to visualize the graph generated by\\ncreate_react_agent\\nand to view an outline of the corresponding code.\\nIt allows you to explore the infrastructure of the agent as defined by the presence of:\\n\\ntools: A list of tools (functions, APIs, or other callable objects) that the agent can use to perform tasks.\\npre_model_hook: A function that is called before the model is invoked. It can be used to condense messages or perform other preprocessing tasks.\\npost_model_hook: A function that is called after the model is invoked. It can be used to implement guardrails, human-in-the-loop flows, or other postprocessing tasks.\\nresponse_format: A data structure used to constrain the type of the final output, e.g., a pydantic BaseModel.\\n\\n\\n\\n\\nFeatures\\n tools\\n pre_model_hook\\n post_model_hook\\n response_format\\n\\n\\n\\nGraph\\n\\n\\n\\nThe following code snippet shows how to create the above agent (and underlying graph) with\\ncreate_react_agent:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                Guides\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                Run an agent\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Copyright © 2025 LangChain, Inc | Consent Preferences\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\"),\n",
       " Document(metadata={'source': 'https://langchain-ai.github.io/langgraph/agents/run_agents/', 'title': 'Run an agent', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRun an agent\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\n            \\n            \\nOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!\\n\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              Run an agent\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Get started\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Additional resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Guides\\n          \\n\\n\\n\\n\\n\\n    Agent development\\n    \\n  \\n\\n\\n\\n\\n\\n            Agent development\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Run an agent\\n    \\n  \\n\\n\\n\\n\\n    Run an agent\\n    \\n  \\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Basic usage\\n    \\n\\n\\n\\n\\n\\n      Inputs and outputs\\n    \\n\\n\\n\\n\\n\\n      Input format\\n    \\n\\n\\n\\n\\n\\n      Output format\\n    \\n\\n\\n\\n\\n\\n      Streaming output\\n    \\n\\n\\n\\n\\n\\n      Max iterations\\n    \\n\\n\\n\\n\\n\\n      Additional Resources\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph APIs\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph APIs\\n          \\n\\n\\n\\n\\n    Graph API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Functional API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Runtime\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Core capabilities\\n    \\n  \\n\\n\\n\\n\\n\\n            Core capabilities\\n          \\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Persistence\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Durable execution\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Context\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Models\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Subgraphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    MCP\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tracing\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Platform-only capabilities\\n    \\n  \\n\\n\\n\\n\\n\\n            Platform-only capabilities\\n          \\n\\n\\n\\n\\n    LangGraph Platform\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Authentication & access control\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Assistants\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Double-texting\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Webhooks\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Cron jobs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Server customization\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Data management\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Additional resources\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Basic usage\\n    \\n\\n\\n\\n\\n\\n      Inputs and outputs\\n    \\n\\n\\n\\n\\n\\n      Input format\\n    \\n\\n\\n\\n\\n\\n      Output format\\n    \\n\\n\\n\\n\\n\\n      Streaming output\\n    \\n\\n\\n\\n\\n\\n      Max iterations\\n    \\n\\n\\n\\n\\n\\n      Additional Resources\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nagent\\n\\n\\n\\n\\nRunning agents¶\\nAgents support both synchronous and asynchronous execution using either .invoke() / await .ainvoke() for full responses, or .stream() / .astream() for incremental streaming output. This section explains how to provide input, interpret output, enable streaming, and control execution limits.\\nBasic usage¶\\nAgents can be executed in two primary modes:\\n\\nSynchronous using .invoke() or .stream()\\nAsynchronous using await .ainvoke() or async for with .astream()\\n\\nSync invocationAsync invocation\\n\\n\\nfrom langgraph.prebuilt import create_react_agent\\n\\nagent = create_react_agent(...)\\n\\nresponse = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]})\\n\\n\\n\\nfrom langgraph.prebuilt import create_react_agent\\n\\nagent = create_react_agent(...)\\nresponse = await agent.ainvoke({\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]})\\n\\n\\n\\n\\nInputs and outputs¶\\nAgents use a language model that expects a list of messages as an input. Therefore, agent inputs and outputs are stored as a list of messages under the messages key in the agent state.\\nInput format¶\\nAgent input must be a dictionary with a messages key. Supported formats are:\\n\\n\\n\\nFormat\\nExample\\n\\n\\n\\n\\nString\\n{\"messages\": \"Hello\"}  — Interpreted as a HumanMessage\\n\\n\\nMessage dictionary\\n{\"messages\": {\"role\": \"user\", \"content\": \"Hello\"}}\\n\\n\\nList of messages\\n{\"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}]}\\n\\n\\nWith custom state\\n{\"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}], \"user_name\": \"Alice\"} — If using a custom state_schema\\n\\n\\n\\nMessages are automatically converted into LangChain\\'s internal message format. You can read\\nmore about LangChain messages in the LangChain documentation.\\n\\nUsing custom agent state\\nYou can provide additional fields defined in your agent’s state schema directly in the input dictionary. This allows dynamic behavior based on runtime data or prior tool outputs.\\nSee the context guide for full details.\\n\\n\\nNote\\nA string input for messages is converted to a HumanMessage. This behavior differs from the prompt parameter in create_react_agent, which is interpreted as a SystemMessage when passed as a string.\\n\\nOutput format¶\\nAgent output is a dictionary containing:\\n\\nmessages: A list of all messages exchanged during execution (user input, assistant replies, tool invocations).\\nOptionally, structured_response if structured output is configured.\\nIf using a custom state_schema, additional keys corresponding to your defined fields may also be present in the output. These can hold updated state values from tool execution or prompt logic.\\n\\nSee the context guide for more details on working with custom state schemas and accessing context.\\nStreaming output¶\\nAgents support streaming responses for more responsive applications. This includes:\\n\\nProgress updates after each step\\nLLM tokens as they\\'re generated\\nCustom tool messages during execution\\n\\nStreaming is available in both sync and async modes:\\nSync streamingAsync streaming\\n\\n\\nfor chunk in agent.stream(\\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]},\\n    stream_mode=\"updates\"\\n):\\n    print(chunk)\\n\\n\\n\\nasync for chunk in agent.astream(\\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]},\\n    stream_mode=\"updates\"\\n):\\n    print(chunk)\\n\\n\\n\\n\\n\\nTip\\nFor full details, see the streaming guide.\\n\\nMax iterations¶\\nTo control agent execution and avoid infinite loops, set a recursion limit. This defines the maximum number of steps the agent can take before raising a GraphRecursionError. You can configure recursion_limit at runtime or when defining agent via .with_config():\\nRuntime.with_config()\\n\\n\\nfrom langgraph.errors import GraphRecursionError\\nfrom langgraph.prebuilt import create_react_agent\\n\\nmax_iterations = 3\\nrecursion_limit = 2 * max_iterations + 1\\nagent = create_react_agent(\\n    model=\"anthropic:claude-3-5-haiku-latest\",\\n    tools=[get_weather]\\n)\\n\\ntry:\\n    response = agent.invoke(\\n        {\"messages\": [{\"role\": \"user\", \"content\": \"what\\'s the weather in sf\"}]},\\n        {\"recursion_limit\": recursion_limit},\\n    )\\nexcept GraphRecursionError:\\n    print(\"Agent stopped due to max iterations.\")\\n\\n\\n\\nfrom langgraph.errors import GraphRecursionError\\nfrom langgraph.prebuilt import create_react_agent\\n\\nmax_iterations = 3\\nrecursion_limit = 2 * max_iterations + 1\\nagent = create_react_agent(\\n    model=\"anthropic:claude-3-5-haiku-latest\",\\n    tools=[get_weather]\\n)\\nagent_with_recursion_limit = agent.with_config(recursion_limit=recursion_limit)\\n\\ntry:\\n    response = agent_with_recursion_limit.invoke(\\n        {\"messages\": [{\"role\": \"user\", \"content\": \"what\\'s the weather in sf\"}]},\\n    )\\nexcept GraphRecursionError:\\n    print(\"Agent stopped due to max iterations.\")\\n\\n\\n\\n\\nAdditional Resources¶\\n\\nAsync programming in LangChain\\n\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                Overview\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                Overview\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Copyright © 2025 LangChain, Inc | Consent Preferences\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_list=list()\n",
    "for sublist in docs:\n",
    "    for item in sublist:\n",
    "        doc_list.append(item)\n",
    "\n",
    "#doc_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5642e064",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000 , chunk_overlap = 200)\n",
    "\n",
    "doc_splits = text_splitter.split_documents(doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be0d06a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(documents=doc_list,embedding=OpenAIEmbeddings())\n",
    "\n",
    "retriver = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f186ad96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='b3ad2380-68a6-4d52-bc8c-20fc68f16d6e', metadata={'source': 'https://langchain-ai.github.io/langgraph/guides/', 'title': 'Guides', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content=\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGuides\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\n            \\n            \\nOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!\\n\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              Guides\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Get started\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Additional resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Guides\\n          \\n\\n\\n\\n\\n\\n    Agent development\\n    \\n  \\n\\n\\n\\n\\n\\n            Agent development\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Run an agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph APIs\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph APIs\\n          \\n\\n\\n\\n\\n    Graph API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Functional API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Runtime\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Core capabilities\\n    \\n  \\n\\n\\n\\n\\n\\n            Core capabilities\\n          \\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Persistence\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Durable execution\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Context\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Models\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Subgraphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    MCP\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tracing\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Platform-only capabilities\\n    \\n  \\n\\n\\n\\n\\n\\n            Platform-only capabilities\\n          \\n\\n\\n\\n\\n    LangGraph Platform\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Authentication & access control\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Assistants\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Double-texting\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Webhooks\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Cron jobs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Server customization\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Data management\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Additional resources\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Agent development\\n    \\n\\n\\n\\n\\n\\n      LangGraph APIs\\n    \\n\\n\\n\\n\\n\\n      Core capabilities\\n    \\n\\n\\n\\n\\n\\n      Platform-only capabilities\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGuides¶\\nThe pages in this section provide a conceptual overview and how-tos for the following topics:\\nAgent development¶\\n\\nOverview: Use prebuilt components to build an agent.\\nRun an agent: Run an agent by providing input, interpreting output, enabling streaming, and controlling execution limits.\\n\\nLangGraph APIs¶\\n\\nGraph API: Use the Graph API to define workflows using a graph paradigm.\\nFunctional API: Use Functional API to build workflows using a functional paradigm without thinking about the graph structure.\\nRuntime: Pregel implements LangGraph's runtime, managing the execution of LangGraph applications.\\n\\nCore capabilities¶\\nThese capabilities are available in both LangGraph OSS and the LangGraph Platform.\\n\\nStreaming: Stream outputs from a LangGraph graph.\\nPersistence: Persist the state of a LangGraph graph.\\nDurable execution: Save progress at key points in the graph execution.\\nMemory: Remember information about previous interactions.\\nContext: Pass outside data to a LangGraph graph to provide context for the graph execution.\\nModels: Integrate various LLMs into your LangGraph application.\\nTools: Interface directly with external systems.\\nHuman-in-the-loop: Pause a graph and wait for human input at any point in a workflow.\\nTime travel: Travel back in time to a specific point in the execution of a LangGraph graph.\\nSubgraphs: Build modular graphs.\\nMulti-agent: Break down a complex workflow into multiple agents.\\nMCP: Use MCP servers in a LangGraph graph.\\nEvaluation: Use LangSmith to evaluate your graph's performance.\\n\\nPlatform-only capabilities¶\\nThese capabilities are only available in LangGraph Platform.\\n\\nAuthentication and access control: Authenticate and authorize users to access a LangGraph graph.\\nAssistants: Build assistants that can be used to interact with a LangGraph graph.\\nDouble-texting: Handle double-texting (consecutive messages before a first response is returned) in a LangGraph graph.\\nWebhooks: Send webhooks to a LangGraph graph.\\nCron jobs: Schedule jobs to run at a specific time.\\nServer customization: Customize the server that runs a LangGraph graph.\\nData management: Manage data in a LangGraph graph.\\nDeployment: Deploy a LangGraph graph to a server.\\n\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                Agent architectures\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                Overview\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Copyright © 2025 LangChain, Inc | Consent Preferences\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\"),\n",
       " Document(id='ec5e49e1-b0e5-4585-a9ec-2537820487bf', metadata={'source': 'https://langchain-ai.github.io/langgraph/agents/overview/', 'title': 'Overview', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content=\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\n            \\n            \\nOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!\\n\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              Overview\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Get started\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Additional resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Guides\\n          \\n\\n\\n\\n\\n\\n    Agent development\\n    \\n  \\n\\n\\n\\n\\n\\n            Agent development\\n          \\n\\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      What is an agent?\\n    \\n\\n\\n\\n\\n\\n      Key features\\n    \\n\\n\\n\\n\\n\\n      High-level building blocks\\n    \\n\\n\\n\\n\\n\\n      Package ecosystem\\n    \\n\\n\\n\\n\\n\\n      Visualize an agent graph\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n    Run an agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph APIs\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph APIs\\n          \\n\\n\\n\\n\\n    Graph API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Functional API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Runtime\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Core capabilities\\n    \\n  \\n\\n\\n\\n\\n\\n            Core capabilities\\n          \\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Persistence\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Durable execution\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Context\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Models\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Subgraphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    MCP\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tracing\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Platform-only capabilities\\n    \\n  \\n\\n\\n\\n\\n\\n            Platform-only capabilities\\n          \\n\\n\\n\\n\\n    LangGraph Platform\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Authentication & access control\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Assistants\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Double-texting\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Webhooks\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Cron jobs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Server customization\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Data management\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Additional resources\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      What is an agent?\\n    \\n\\n\\n\\n\\n\\n      Key features\\n    \\n\\n\\n\\n\\n\\n      High-level building blocks\\n    \\n\\n\\n\\n\\n\\n      Package ecosystem\\n    \\n\\n\\n\\n\\n\\n      Visualize an agent graph\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nagent\\n\\n\\n\\n\\nAgent development using prebuilt components¶\\nLangGraph provides both low-level primitives and high-level prebuilt components for building agent-based applications. This section focuses on the prebuilt, ready-to-use components designed to help you construct agentic systems quickly and reliably—without the need to implement orchestration, memory, or human feedback handling from scratch.\\nWhat is an agent?¶\\nAn agent consists of three components: a large language model (LLM), a set of tools it can use, and a prompt that provides instructions.\\nThe LLM operates in a loop. In each iteration, it selects a tool to invoke, provides input, receives the result (an observation), and uses that observation to inform the next action. The loop continues until a stopping condition is met — typically when the agent has gathered enough information to respond to the user.\\n\\n\\nAgent loop: the LLM selects tools and uses their outputs to fulfill a user request.\\n\\nKey features¶\\nLangGraph includes several capabilities essential for building robust, production-ready agentic systems:\\n\\nMemory integration: Native support for short-term (session-based) and long-term (persistent across sessions) memory, enabling stateful behaviors in chatbots and assistants.\\nHuman-in-the-loop control: Execution can pause indefinitely to await human feedback—unlike websocket-based solutions limited to real-time interaction. This enables asynchronous approval, correction, or intervention at any point in the workflow.\\nStreaming support: Real-time streaming of agent state, model tokens, tool outputs, or combined streams.\\nDeployment tooling: Includes infrastructure-free deployment tools. LangGraph Platform supports testing, debugging, and deployment.\\nStudio: A visual IDE for inspecting and debugging workflows.\\nSupports multiple deployment options for production.\\n\\n\\n\\nHigh-level building blocks¶\\nLangGraph comes with a set of prebuilt components that implement common agent behaviors and workflows. These abstractions are built on top of the LangGraph framework, offering a faster path to production while remaining flexible for advanced customization.\\nUsing LangGraph for agent development allows you to focus on your application's logic and behavior, instead of building and maintaining the supporting infrastructure for state, memory, and human feedback.\\nPackage ecosystem¶\\nThe high-level components are organized into several packages, each with a specific focus.\\n\\n\\n\\nPackage\\nDescription\\nInstallation\\n\\n\\n\\n\\nlanggraph-prebuilt (part of langgraph)\\nPrebuilt components to create agents\\npip install -U langgraph langchain\\n\\n\\nlanggraph-supervisor\\nTools for building supervisor agents\\npip install -U langgraph-supervisor\\n\\n\\nlanggraph-swarm\\nTools for building a swarm multi-agent system\\npip install -U langgraph-swarm\\n\\n\\nlangchain-mcp-adapters\\nInterfaces to MCP servers for tool and resource integration\\npip install -U langchain-mcp-adapters\\n\\n\\nlangmem\\nAgent memory management: short-term and long-term\\npip install -U langmem\\n\\n\\nagentevals\\nUtilities to evaluate agent performance\\npip install -U agentevals\\n\\n\\n\\nVisualize an agent graph¶\\nUse the following tool to visualize the graph generated by\\ncreate_react_agent\\nand to view an outline of the corresponding code.\\nIt allows you to explore the infrastructure of the agent as defined by the presence of:\\n\\ntools: A list of tools (functions, APIs, or other callable objects) that the agent can use to perform tasks.\\npre_model_hook: A function that is called before the model is invoked. It can be used to condense messages or perform other preprocessing tasks.\\npost_model_hook: A function that is called after the model is invoked. It can be used to implement guardrails, human-in-the-loop flows, or other postprocessing tasks.\\nresponse_format: A data structure used to constrain the type of the final output, e.g., a pydantic BaseModel.\\n\\n\\n\\n\\nFeatures\\n tools\\n pre_model_hook\\n post_model_hook\\n response_format\\n\\n\\n\\nGraph\\n\\n\\n\\nThe following code snippet shows how to create the above agent (and underlying graph) with\\ncreate_react_agent:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                Guides\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                Run an agent\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Copyright © 2025 LangChain, Inc | Consent Preferences\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\"),\n",
       " Document(id='d0b06724-837f-49d3-a9ef-0a780e289122', metadata={'source': 'https://langchain-ai.github.io/langgraph/agents/run_agents/', 'title': 'Run an agent', 'description': 'Build reliable, stateful AI systems, without giving up control', 'language': 'en'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRun an agent\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\n            \\n            \\nOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!\\n\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              Run an agent\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Get started\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Additional resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Guides\\n          \\n\\n\\n\\n\\n\\n    Agent development\\n    \\n  \\n\\n\\n\\n\\n\\n            Agent development\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Run an agent\\n    \\n  \\n\\n\\n\\n\\n    Run an agent\\n    \\n  \\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Basic usage\\n    \\n\\n\\n\\n\\n\\n      Inputs and outputs\\n    \\n\\n\\n\\n\\n\\n      Input format\\n    \\n\\n\\n\\n\\n\\n      Output format\\n    \\n\\n\\n\\n\\n\\n      Streaming output\\n    \\n\\n\\n\\n\\n\\n      Max iterations\\n    \\n\\n\\n\\n\\n\\n      Additional Resources\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph APIs\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph APIs\\n          \\n\\n\\n\\n\\n    Graph API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Functional API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Runtime\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Core capabilities\\n    \\n  \\n\\n\\n\\n\\n\\n            Core capabilities\\n          \\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Persistence\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Durable execution\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Context\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Models\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Subgraphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    MCP\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tracing\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Platform-only capabilities\\n    \\n  \\n\\n\\n\\n\\n\\n            Platform-only capabilities\\n          \\n\\n\\n\\n\\n    LangGraph Platform\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Authentication & access control\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Assistants\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Double-texting\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Webhooks\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Cron jobs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Server customization\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Data management\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Additional resources\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Basic usage\\n    \\n\\n\\n\\n\\n\\n      Inputs and outputs\\n    \\n\\n\\n\\n\\n\\n      Input format\\n    \\n\\n\\n\\n\\n\\n      Output format\\n    \\n\\n\\n\\n\\n\\n      Streaming output\\n    \\n\\n\\n\\n\\n\\n      Max iterations\\n    \\n\\n\\n\\n\\n\\n      Additional Resources\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nagent\\n\\n\\n\\n\\nRunning agents¶\\nAgents support both synchronous and asynchronous execution using either .invoke() / await .ainvoke() for full responses, or .stream() / .astream() for incremental streaming output. This section explains how to provide input, interpret output, enable streaming, and control execution limits.\\nBasic usage¶\\nAgents can be executed in two primary modes:\\n\\nSynchronous using .invoke() or .stream()\\nAsynchronous using await .ainvoke() or async for with .astream()\\n\\nSync invocationAsync invocation\\n\\n\\nfrom langgraph.prebuilt import create_react_agent\\n\\nagent = create_react_agent(...)\\n\\nresponse = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]})\\n\\n\\n\\nfrom langgraph.prebuilt import create_react_agent\\n\\nagent = create_react_agent(...)\\nresponse = await agent.ainvoke({\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]})\\n\\n\\n\\n\\nInputs and outputs¶\\nAgents use a language model that expects a list of messages as an input. Therefore, agent inputs and outputs are stored as a list of messages under the messages key in the agent state.\\nInput format¶\\nAgent input must be a dictionary with a messages key. Supported formats are:\\n\\n\\n\\nFormat\\nExample\\n\\n\\n\\n\\nString\\n{\"messages\": \"Hello\"}  — Interpreted as a HumanMessage\\n\\n\\nMessage dictionary\\n{\"messages\": {\"role\": \"user\", \"content\": \"Hello\"}}\\n\\n\\nList of messages\\n{\"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}]}\\n\\n\\nWith custom state\\n{\"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}], \"user_name\": \"Alice\"} — If using a custom state_schema\\n\\n\\n\\nMessages are automatically converted into LangChain\\'s internal message format. You can read\\nmore about LangChain messages in the LangChain documentation.\\n\\nUsing custom agent state\\nYou can provide additional fields defined in your agent’s state schema directly in the input dictionary. This allows dynamic behavior based on runtime data or prior tool outputs.\\nSee the context guide for full details.\\n\\n\\nNote\\nA string input for messages is converted to a HumanMessage. This behavior differs from the prompt parameter in create_react_agent, which is interpreted as a SystemMessage when passed as a string.\\n\\nOutput format¶\\nAgent output is a dictionary containing:\\n\\nmessages: A list of all messages exchanged during execution (user input, assistant replies, tool invocations).\\nOptionally, structured_response if structured output is configured.\\nIf using a custom state_schema, additional keys corresponding to your defined fields may also be present in the output. These can hold updated state values from tool execution or prompt logic.\\n\\nSee the context guide for more details on working with custom state schemas and accessing context.\\nStreaming output¶\\nAgents support streaming responses for more responsive applications. This includes:\\n\\nProgress updates after each step\\nLLM tokens as they\\'re generated\\nCustom tool messages during execution\\n\\nStreaming is available in both sync and async modes:\\nSync streamingAsync streaming\\n\\n\\nfor chunk in agent.stream(\\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]},\\n    stream_mode=\"updates\"\\n):\\n    print(chunk)\\n\\n\\n\\nasync for chunk in agent.astream(\\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]},\\n    stream_mode=\"updates\"\\n):\\n    print(chunk)\\n\\n\\n\\n\\n\\nTip\\nFor full details, see the streaming guide.\\n\\nMax iterations¶\\nTo control agent execution and avoid infinite loops, set a recursion limit. This defines the maximum number of steps the agent can take before raising a GraphRecursionError. You can configure recursion_limit at runtime or when defining agent via .with_config():\\nRuntime.with_config()\\n\\n\\nfrom langgraph.errors import GraphRecursionError\\nfrom langgraph.prebuilt import create_react_agent\\n\\nmax_iterations = 3\\nrecursion_limit = 2 * max_iterations + 1\\nagent = create_react_agent(\\n    model=\"anthropic:claude-3-5-haiku-latest\",\\n    tools=[get_weather]\\n)\\n\\ntry:\\n    response = agent.invoke(\\n        {\"messages\": [{\"role\": \"user\", \"content\": \"what\\'s the weather in sf\"}]},\\n        {\"recursion_limit\": recursion_limit},\\n    )\\nexcept GraphRecursionError:\\n    print(\"Agent stopped due to max iterations.\")\\n\\n\\n\\nfrom langgraph.errors import GraphRecursionError\\nfrom langgraph.prebuilt import create_react_agent\\n\\nmax_iterations = 3\\nrecursion_limit = 2 * max_iterations + 1\\nagent = create_react_agent(\\n    model=\"anthropic:claude-3-5-haiku-latest\",\\n    tools=[get_weather]\\n)\\nagent_with_recursion_limit = agent.with_config(recursion_limit=recursion_limit)\\n\\ntry:\\n    response = agent_with_recursion_limit.invoke(\\n        {\"messages\": [{\"role\": \"user\", \"content\": \"what\\'s the weather in sf\"}]},\\n    )\\nexcept GraphRecursionError:\\n    print(\"Agent stopped due to max iterations.\")\\n\\n\\n\\n\\nAdditional Resources¶\\n\\nAsync programming in LangChain\\n\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                Overview\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                Overview\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Copyright © 2025 LangChain, Inc | Consent Preferences\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriver.invoke(\"what is lang graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12c5b7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriver_tool = create_retriever_tool(retriver,\"retriver_vector_langgraph_blog\",\"search and run information about langgraph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94331e10",
   "metadata": {},
   "source": [
    "### langchain blogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97685432",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://python.langchain.com/docs/introduction/\",\n",
    "    \"https://python.langchain.com/docs/tutorials/\",\n",
    "    \"https://python.langchain.com/docs/how_to/\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f862b3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs\n",
    "\n",
    "doc_list=list()\n",
    "for sublist in docs:\n",
    "    for item in sublist:\n",
    "        doc_list.append(item)\n",
    "\n",
    "doc_splits = text_splitter.split_documents(doc_list)\n",
    "\n",
    "vectorstore_langchain = FAISS.from_documents(documents=doc_list,embedding=OpenAIEmbeddings())\n",
    "retrival_langchain = vectorstore_langchain.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e9d180d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrival_tool_langchain = create_retriever_tool(\n",
    "    retrival_langchain,\n",
    "    \"retriver_tool_langgrah_blog\",\n",
    "    \"search and run information about langgraph\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d60cfb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [retrival_tool_langchain,retriver_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63b8e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated,Sequence\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages:Annotated[Sequence[BaseMessage],add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c4e3397",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00db6e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(state:AgentState):\n",
    "\n",
    "    \"\"\"\n",
    "    Invokes the agent model to generate a response based on the current state. Given\n",
    "    the question, it will decide to retrieve using the retriever tool, or simply end.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with the agent response appended to messages\n",
    "    \"\"\"\n",
    "    print(\"---CALL AGENT---\")\n",
    "    model = llm.bind_tools(tools)\n",
    "    message =state[\"messages\"]\n",
    "    return {\"messages\":[model.invoke(message)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d26efbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0822c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Edges\n",
    "def grade_documents(state) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        str: A decision for whether the documents are relevant or not\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK RELEVANCE---\")\n",
    "\n",
    "    # Data model\n",
    "    class grade(BaseModel):\n",
    "        \"\"\"Binary score for relevance check.\"\"\"\n",
    "\n",
    "        binary_score: str = Field(description=\"Relevance score 'yes' or 'no'\")\n",
    "\n",
    "    # LLM\n",
    "    model = ChatOpenAI(model = \"gpt-4o\")\n",
    "    # LLM with tool and validation\n",
    "    llm_with_tool = model.with_structured_output(grade)\n",
    "\n",
    "    # Prompt\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "        Here is the retrieved document: \\n\\n {context} \\n\\n\n",
    "        Here is the user question: {question} \\n\n",
    "        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\",\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "\n",
    "    # Chain\n",
    "    chain = prompt | llm_with_tool\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    question = messages[0].content\n",
    "    docs = last_message.content\n",
    "\n",
    "    scored_result = chain.invoke({\"question\": question, \"context\": docs})\n",
    "\n",
    "    score = scored_result.binary_score\n",
    "\n",
    "    if score == \"yes\":\n",
    "        print(\"---DECISION: DOCS RELEVANT---\")\n",
    "        return \"generate\"\n",
    "\n",
    "    else:\n",
    "        print(\"---DECISION: DOCS NOT RELEVANT---\")\n",
    "        print(score)\n",
    "        return \"rewrite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f631df1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\Desktop\\1602_24_733_186\\AGENTICWORKSPACE\\myenv\\Lib\\site-packages\\langsmith\\client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] input_types={} partial_variables={} metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de6d03e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "         dict: The updated message\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    docs = last_message.content\n",
    "\n",
    "    # Prompt\n",
    "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "    # LLM\n",
    "    model = ChatOpenAI(model = \"gpt-4o\")\n",
    "\n",
    "    # Post-processing\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    # Chain\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    # Run\n",
    "    response = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7fb38a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "    Look at the input and try to reason about the underlying semantic intent / meaning. \n",
      " \n",
      "    Here is the initial question:\n",
      "    \n",
      " ------- \n",
      "\n",
      "    {question} \n",
      "    \n",
      " ------- \n",
      "\n",
      "    Formulate an improved question: \n"
     ]
    }
   ],
   "source": [
    "print(\"\"\" \\n \n",
    "    Look at the input and try to reason about the underlying semantic intent / meaning. \\n \n",
    "    Here is the initial question:\n",
    "    \\n ------- \\n\n",
    "    {question} \n",
    "    \\n ------- \\n\n",
    "    Formulate an improved question: \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a69e8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with re-phrased question\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "\n",
    "    msg = [\n",
    "        HumanMessage(\n",
    "            content=f\"\"\" \\n \n",
    "    Look at the input and try to reason about the underlying semantic intent / meaning. \\n \n",
    "    Here is the initial question:\n",
    "    \\n ------- \\n\n",
    "    {question} \n",
    "    \\n ------- \\n\n",
    "    Formulate an improved question: \"\"\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    model = ChatOpenAI(model = \"gpt-4o\")\n",
    "    response = model.invoke(msg)\n",
    "    return {\"messages\": [response]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a643b328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the nodes we will cycle between\n",
    "workflow.add_node(\"agent\", agent)  # agent\n",
    "retrieve = ToolNode(tools=tools)\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieval\n",
    "workflow.add_node(\"rewrite\", rewrite)  # Re-writing the question\n",
    "workflow.add_node(\n",
    "    \"generate\", generate\n",
    ")  # Generating a response after we know the documents are relevant\n",
    "# Call agent node to decide to retrieve or not\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# Decide whether to retrieve\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    # Assess agent decision\n",
    "    tools_condition,\n",
    "    {\n",
    "        # Translate the condition outputs to nodes in our graph\n",
    "        \"tools\": \"retrieve\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Edges taken after the `action` node is called.\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    # Assess agent decision\n",
    "    grade_documents,\n",
    ")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "workflow.add_edge(\"rewrite\", \"agent\")\n",
    "\n",
    "# Compile\n",
    "graph = workflow.compile()\n",
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc6a2601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CALL AGENT---\n",
      "---CHECK RELEVANCE---\n",
      "---DECISION: DOCS RELEVANT---\n",
      "---GENERATE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\Desktop\\1602_24_733_186\\AGENTICWORKSPACE\\myenv\\Lib\\site-packages\\langsmith\\client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is Langgraph?', additional_kwargs={}, response_metadata={}, id='595fefea-ec18-4582-828d-6a6c573c89a5'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_q5JBr6uvZrXJotf8C3AJuyf1', 'function': {'arguments': '{\"query\": \"Langgraph\"}', 'name': 'retriver_tool_langgrah_blog'}, 'type': 'function'}, {'id': 'call_tFJ5eThYE5hYJpN2dUPypIgZ', 'function': {'arguments': '{\"query\": \"Langgraph\"}', 'name': 'retriver_vector_langgraph_blog'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 99, 'total_tokens': 156, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-BybR9Pto9NTgZ1bvh7nUHzC33RdDZ', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--ca95f0db-c20b-45f4-a6e3-c5e419e8126c-0', tool_calls=[{'name': 'retriver_tool_langgrah_blog', 'args': {'query': 'Langgraph'}, 'id': 'call_q5JBr6uvZrXJotf8C3AJuyf1', 'type': 'tool_call'}, {'name': 'retriver_vector_langgraph_blog', 'args': {'query': 'Langgraph'}, 'id': 'call_tFJ5eThYE5hYJpN2dUPypIgZ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 99, 'output_tokens': 57, 'total_tokens': 156, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='\\n\\n\\n\\n\\nIntroduction | 🦜️🔗 LangChain\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1💬SearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a modelHow to summarize text through parallelizationHow to summarize text through iterative refinementHow to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query analysisHow to use built-in tools and toolkitsHow to pass through arguments from one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain\\'s stateHow to construct filters for query analysisHow to configure runtime chain internalsHow deal with high cardinality categoricals when doing query analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track token usage in ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval with contextual compressionHow to convert Runnables to ToolsHow to create custom callback handlersHow to create a custom chat model classCustom EmbeddingsHow to create a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram overlapHow to select examples by similarityHow to use reference examples when doing extractionHow to handle long text when doing extractionHow to use prompting alone (no tool calling) to do extractionHow to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect runnablesLangChain Expression Language CheatsheetHow to cache LLM responsesHow to track token usage for LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved results to mitigate the \"lost in the middle\" effectHow to split Markdown by HeadersHow to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data to modelsHow to use multimodal promptsHow to create a custom Output ParserHow to use the output-fixing parserHow to parse JSON outputHow to retry when a parsing error occursHow to parse text from message objectsHow to parse XML outputHow to parse YAML outputHow to use the Parent Document RetrieverHow to use LangChain with different Pydantic versionsHow to add chat historyHow to get a RAG application to add citationsHow to do per-user retrievalHow to get your RAG application to return sourcesHow to stream results from your RAG applicationHow to split JSON dataHow to recursively split text by charactersResponse metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with langchainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured outputsTestingString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?Ecosystem🦜🛠️ LangSmith🦜🕸️ LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyIntroductionOn this pageIntroduction\\nLangChain is a framework for developing applications powered by large language models (LLMs).\\nLangChain simplifies every stage of the LLM application lifecycle:\\n\\nDevelopment: Build your applications using LangChain\\'s open-source components and third-party integrations.\\nUse LangGraph to build stateful agents with first-class streaming and human-in-the-loop support.\\nProductionization: Use LangSmith to inspect, monitor and evaluate your applications, so that you can continuously optimize and deploy with confidence.\\nDeployment: Turn your LangGraph applications into production-ready APIs and Assistants with LangGraph Platform.\\n\\n\\n\\nLangChain implements a standard interface for large language models and related\\ntechnologies, such as embedding models and vector stores, and integrates with\\nhundreds of providers. See the integrations page for\\nmore.\\n\\nSelect chat model:Google Gemini▾OpenAIAnthropicAzureGoogle GeminiGoogle VertexAWSGroqCohereNVIDIAFireworks AIMistral AITogether AIIBM watsonxDatabricksxAIPerplexitypip install -qU \"langchain[google-genai]\"import getpassimport osif not os.environ.get(\"GOOGLE_API_KEY\"):  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")from langchain.chat_models import init_chat_modelmodel = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")\\nmodel.invoke(\"Hello, world!\")\\nnoteThese docs focus on the Python LangChain library. Head here for docs on the JavaScript LangChain library.\\nArchitecture\\u200b\\nThe LangChain framework consists of multiple open-source libraries. Read more in the\\nArchitecture page.\\n\\nlangchain-core: Base abstractions for chat models and other components.\\nIntegration packages (e.g. langchain-openai, langchain-anthropic, etc.): Important integrations have been split into lightweight packages that are co-maintained by the LangChain team and the integration developers.\\nlangchain: Chains, agents, and retrieval strategies that make up an application\\'s cognitive architecture.\\nlangchain-community: Third-party integrations that are community maintained.\\nlanggraph: Orchestration framework for combining LangChain components into production-ready applications with persistence, streaming, and other key features. See LangGraph documentation.\\n\\nGuides\\u200b\\nTutorials\\u200b\\nIf you\\'re looking to build something specific or are more of a hands-on learner, check out our tutorials section.\\nThis is the best place to get started.\\nThese are the best ones to get started with:\\n\\nBuild a Simple LLM Application\\nBuild a Chatbot\\nBuild an Agent\\nIntroduction to LangGraph\\n\\nExplore the full list of LangChain tutorials here, and check out other LangGraph tutorials here. To learn more about LangGraph, check out our first LangChain Academy course, Introduction to LangGraph, available here.\\nHow-to guides\\u200b\\nHere you’ll find short answers to “How do I….?” types of questions.\\nThese how-to guides don’t cover topics in depth – you’ll find that material in the Tutorials and the API Reference.\\nHowever, these guides will help you quickly accomplish common tasks using chat models,\\nvector stores, and other common LangChain components.\\nCheck out LangGraph-specific how-tos here.\\nConceptual guide\\u200b\\nIntroductions to all the key parts of LangChain you’ll need to know! Here you\\'ll find high level explanations of all LangChain concepts.\\nFor a deeper dive into LangGraph concepts, check out this page.\\nIntegrations\\u200b\\nLangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it.\\nIf you\\'re looking to get up and running quickly with chat models, vector stores,\\nor other LangChain components from a specific provider, check out our growing list of integrations.\\nAPI reference\\u200b\\nHead to the reference section for full documentation of all classes and methods in the LangChain Python packages.\\nEcosystem\\u200b\\n🦜🛠️ LangSmith\\u200b\\nTrace and evaluate your language model applications and intelligent agents to help you move from prototype to production.\\n🦜🕸️ LangGraph\\u200b\\nBuild stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it. LangGraph powers production-grade agents, trusted by Linkedin, Uber, Klarna, GitLab, and many more.\\nAdditional resources\\u200b\\nVersions\\u200b\\nSee what changed in v0.3, learn how to migrate legacy code, read up on our versioning policies, and more.\\nSecurity\\u200b\\nRead up on security best practices to make sure you\\'re developing safely with LangChain.\\nContributing\\u200b\\nCheck out the developer\\'s guide for guidelines on contributing and help getting your dev environment set up.Edit this pageNextTutorialsArchitectureGuidesTutorialsHow-to guidesConceptual guideIntegrationsAPI referenceEcosystem🦜🛠️ LangSmith🦜🕸️ LangGraphAdditional resourcesVersionsSecurityContributingCommunityLangChain ForumTwitterSlackGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright © 2025 LangChain, Inc.\\n\\n\\n\\n\\n\\n\\n\\n\\nTutorials | 🦜️🔗 LangChain\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1💬SearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a modelHow to summarize text through parallelizationHow to summarize text through iterative refinementHow to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query analysisHow to use built-in tools and toolkitsHow to pass through arguments from one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain\\'s stateHow to construct filters for query analysisHow to configure runtime chain internalsHow deal with high cardinality categoricals when doing query analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track token usage in ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval with contextual compressionHow to convert Runnables to ToolsHow to create custom callback handlersHow to create a custom chat model classCustom EmbeddingsHow to create a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram overlapHow to select examples by similarityHow to use reference examples when doing extractionHow to handle long text when doing extractionHow to use prompting alone (no tool calling) to do extractionHow to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect runnablesLangChain Expression Language CheatsheetHow to cache LLM responsesHow to track token usage for LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved results to mitigate the \"lost in the middle\" effectHow to split Markdown by HeadersHow to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data to modelsHow to use multimodal promptsHow to create a custom Output ParserHow to use the output-fixing parserHow to parse JSON outputHow to retry when a parsing error occursHow to parse text from message objectsHow to parse XML outputHow to parse YAML outputHow to use the Parent Document RetrieverHow to use LangChain with different Pydantic versionsHow to add chat historyHow to get a RAG application to add citationsHow to do per-user retrievalHow to get your RAG application to return sourcesHow to stream results from your RAG applicationHow to split JSON dataHow to recursively split text by charactersResponse metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with langchainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured outputsTestingString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?Ecosystem🦜🛠️ LangSmith🦜🕸️ LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyTutorialsOn this pageTutorials\\nNew to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.\\nGet started\\u200b\\nFamiliarize yourself with LangChain\\'s open-source components by building simple applications.\\nIf you\\'re looking to get started with chat models, vector stores,\\nor other LangChain components from a specific provider, check out our supported integrations.\\n\\nChat models and prompts: Build a simple LLM application with prompt templates and chat models.\\nSemantic search: Build a semantic search engine over a PDF with document loaders, embedding models, and vector stores.\\nClassification: Classify text into categories or labels using chat models with structured outputs.\\nExtraction: Extract structured data from text and other unstructured media using chat models and few-shot examples.\\n\\nRefer to the how-to guides for more detail on using all LangChain components.\\nOrchestration\\u200b\\nGet started using LangGraph to assemble LangChain components into full-featured applications.\\n\\nChatbots: Build a chatbot that incorporates memory.\\nAgents: Build an agent that interacts with external tools.\\nRetrieval Augmented Generation (RAG) Part 1: Build an application that uses your own documents to inform its responses.\\nRetrieval Augmented Generation (RAG) Part 2: Build a RAG application that incorporates a memory of its user interactions and multi-step retrieval.\\nQuestion-Answering with SQL: Build a question-answering system that executes SQL queries to inform its responses.\\nSummarization: Generate summaries of (potentially long) texts.\\nQuestion-Answering with Graph Databases: Build a question-answering system that queries a graph database to inform its responses.\\n\\nLangSmith\\u200b\\nLangSmith allows you to closely trace, monitor and evaluate your LLM application.\\nIt seamlessly integrates with LangChain, and you can use it to inspect and debug individual steps of your chains as you build.\\nLangSmith documentation is hosted on a separate site.\\nYou can peruse LangSmith tutorials here.\\nEvaluation\\u200b\\nLangSmith helps you evaluate the performance of your LLM applications. The tutorial below is a great way to get started:\\n\\nEvaluate your LLM application\\nEdit this pagePreviousIntroductionNextBuild a Question Answering application over a Graph DatabaseGet startedOrchestrationLangSmithEvaluationCommunityLangChain ForumTwitterSlackGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright © 2025 LangChain, Inc.\\n\\n\\n\\n\\n\\n\\n\\n\\nHow-to guides | 🦜️🔗 LangChain\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1💬SearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a modelHow to summarize text through parallelizationHow to summarize text through iterative refinementHow to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query analysisHow to use built-in tools and toolkitsHow to pass through arguments from one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain\\'s stateHow to construct filters for query analysisHow to configure runtime chain internalsHow deal with high cardinality categoricals when doing query analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track token usage in ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval with contextual compressionHow to convert Runnables to ToolsHow to create custom callback handlersHow to create a custom chat model classCustom EmbeddingsHow to create a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram overlapHow to select examples by similarityHow to use reference examples when doing extractionHow to handle long text when doing extractionHow to use prompting alone (no tool calling) to do extractionHow to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect runnablesLangChain Expression Language CheatsheetHow to cache LLM responsesHow to track token usage for LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved results to mitigate the \"lost in the middle\" effectHow to split Markdown by HeadersHow to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data to modelsHow to use multimodal promptsHow to create a custom Output ParserHow to use the output-fixing parserHow to parse JSON outputHow to retry when a parsing error occursHow to parse text from message objectsHow to parse XML outputHow to parse YAML outputHow to use the Parent Document RetrieverHow to use LangChain with different Pydantic versionsHow to add chat historyHow to get a RAG application to add citationsHow to do per-user retrievalHow to get your RAG application to return sourcesHow to stream results from your RAG applicationHow to split JSON dataHow to recursively split text by charactersResponse metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with langchainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured outputsTestingString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?Ecosystem🦜🛠️ LangSmith🦜🕸️ LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyHow-to guidesOn this pageHow-to guides\\nHere you’ll find answers to “How do I….?” types of questions.\\nThese guides are goal-oriented and concrete; they\\'re meant to help you complete a specific task.\\nFor conceptual explanations see the Conceptual guide.\\nFor end-to-end walkthroughs see Tutorials.\\nFor comprehensive descriptions of every class and function see the API Reference.\\nInstallation\\u200b\\n\\nHow to: install LangChain packages\\nHow to: use LangChain with different Pydantic versions\\n\\nKey features\\u200b\\nThis highlights functionality that is core to using LangChain.\\n\\nHow to: return structured data from a model\\nHow to: use a model to call tools\\nHow to: stream runnables\\nHow to: debug your LLM apps\\n\\nComponents\\u200b\\nThese are the core building blocks you can use when building applications.\\nChat models\\u200b\\nChat Models are newer forms of language models that take messages in and output a message.\\nSee supported integrations for details on getting started with chat models from a specific provider.\\n\\nHow to: init any model in one line\\nHow to: work with local models\\nHow to: do function/tool calling\\nHow to: get models to return structured output\\nHow to: cache model responses\\nHow to: get log probabilities\\nHow to: create a custom chat model class\\nHow to: stream a response back\\nHow to: track token usage\\nHow to: track response metadata across providers\\nHow to: use chat model to call tools\\nHow to: stream tool calls\\nHow to: handle rate limits\\nHow to: few shot prompt tool behavior\\nHow to: bind model-specific formatted tools\\nHow to: force a specific tool call\\nHow to: pass multimodal data directly to models\\n\\nMessages\\u200b\\nMessages are the input and output of chat models. They have some content and a role, which describes the source of the message.\\n\\nHow to: trim messages\\nHow to: filter messages\\nHow to: merge consecutive messages of the same type\\n\\nPrompt templates\\u200b\\nPrompt Templates are responsible for formatting user input into a format that can be passed to a language model.\\n\\nHow to: use few shot examples\\nHow to: use few shot examples in chat models\\nHow to: partially format prompt templates\\nHow to: compose prompts together\\nHow to: use multimodal prompts\\n\\nExample selectors\\u200b\\nExample Selectors are responsible for selecting the correct few shot examples to pass to the prompt.\\n\\nHow to: use example selectors\\nHow to: select examples by length\\nHow to: select examples by semantic similarity\\nHow to: select examples by semantic ngram overlap\\nHow to: select examples by maximal marginal relevance\\nHow to: select examples from LangSmith few-shot datasets\\n\\nLLMs\\u200b\\nWhat LangChain calls LLMs are older forms of language models that take a string in and output a string.\\n\\nHow to: cache model responses\\nHow to: create a custom LLM class\\nHow to: stream a response back\\nHow to: track token usage\\nHow to: work with local models\\n\\nOutput parsers\\u200b\\nOutput Parsers are responsible for taking the output of an LLM and parsing into more structured format.\\n\\nHow to: parse text from message objects\\nHow to: use output parsers to parse an LLM response into structured format\\nHow to: parse JSON output\\nHow to: parse XML output\\nHow to: parse YAML output\\nHow to: retry when output parsing errors occur\\nHow to: try to fix errors in output parsing\\nHow to: write a custom output parser class\\n\\nDocument loaders\\u200b\\nDocument Loaders are responsible for loading documents from a variety of sources.\\n\\nHow to: load PDF files\\nHow to: load web pages\\nHow to: load CSV data\\nHow to: load data from a directory\\nHow to: load HTML data\\nHow to: load JSON data\\nHow to: load Markdown data\\nHow to: load Microsoft Office data\\nHow to: write a custom document loader\\n\\nText splitters\\u200b\\nText Splitters take a document and split into chunks that can be used for retrieval.\\n\\nHow to: recursively split text\\nHow to: split HTML\\nHow to: split by character\\nHow to: split code\\nHow to: split Markdown by headers\\nHow to: recursively split JSON\\nHow to: split text into semantic chunks\\nHow to: split by tokens\\n\\nEmbedding models\\u200b\\nEmbedding Models take a piece of text and create a numerical representation of it.\\nSee supported integrations for details on getting started with embedding models from a specific provider.\\n\\nHow to: embed text data\\nHow to: cache embedding results\\nHow to: create a custom embeddings class\\n\\nVector stores\\u200b\\nVector stores are databases that can efficiently store and retrieve embeddings.\\nSee supported integrations for details on getting started with vector stores from a specific provider.\\n\\nHow to: use a vector store to retrieve data\\n\\nRetrievers\\u200b\\nRetrievers are responsible for taking a query and returning relevant documents.\\n\\nHow to: use a vector store to retrieve data\\nHow to: generate multiple queries to retrieve data for\\nHow to: use contextual compression to compress the data retrieved\\nHow to: write a custom retriever class\\nHow to: add similarity scores to retriever results\\nHow to: combine the results from multiple retrievers\\nHow to: reorder retrieved results to mitigate the \"lost in the middle\" effect\\nHow to: generate multiple embeddings per document\\nHow to: retrieve the whole document for a chunk\\nHow to: generate metadata filters\\nHow to: create a time-weighted retriever\\nHow to: use hybrid vector and keyword retrieval\\n\\nIndexing\\u200b\\nIndexing is the process of keeping your vectorstore in-sync with the underlying data source.\\n\\nHow to: reindex data to keep your vectorstore in-sync with the underlying data source\\n\\nTools\\u200b\\nLangChain Tools contain a description of the tool (to pass to the language model) as well as the implementation of the function to call. Refer here for a list of pre-built tools.\\n\\nHow to: create tools\\nHow to: use built-in tools and toolkits\\nHow to: use chat models to call tools\\nHow to: pass tool outputs to chat models\\nHow to: pass run time values to tools\\nHow to: add a human-in-the-loop for tools\\nHow to: handle tool errors\\nHow to: force models to call a tool\\nHow to: disable parallel tool calling\\nHow to: access the RunnableConfig from a tool\\nHow to: stream events from a tool\\nHow to: return artifacts from a tool\\nHow to: convert Runnables to tools\\nHow to: add ad-hoc tool calling capability to models\\nHow to: pass in runtime secrets\\n\\nMultimodal\\u200b\\n\\nHow to: pass multimodal data directly to models\\nHow to: use multimodal prompts\\n\\nAgents\\u200b\\nnoteFor in depth how-to guides for agents, please check out LangGraph documentation.\\n\\nHow to: use legacy LangChain Agents (AgentExecutor)\\nHow to: migrate from legacy LangChain agents to LangGraph\\n\\nCallbacks\\u200b\\nCallbacks allow you to hook into the various stages of your LLM application\\'s execution.\\n\\nHow to: pass in callbacks at runtime\\nHow to: attach callbacks to a module\\nHow to: pass callbacks into a module constructor\\nHow to: create custom callback handlers\\nHow to: use callbacks in async environments\\nHow to: dispatch custom callback events\\n\\nCustom\\u200b\\nAll of LangChain components can easily be extended to support your own versions.\\n\\nHow to: create a custom chat model class\\nHow to: create a custom LLM class\\nHow to: create a custom embeddings class\\nHow to: write a custom retriever class\\nHow to: write a custom document loader\\nHow to: write a custom output parser class\\nHow to: create custom callback handlers\\nHow to: define a custom tool\\nHow to: dispatch custom callback events\\n\\nSerialization\\u200b\\n\\nHow to: save and load LangChain objects\\n\\nUse cases\\u200b\\nThese guides cover use-case specific details.\\nQ&A with RAG\\u200b\\nRetrieval Augmented Generation (RAG) is a way to connect LLMs to external sources of data.\\nFor a high-level tutorial on RAG, check out this guide.\\n\\nHow to: add chat history\\nHow to: stream\\nHow to: return sources\\nHow to: return citations\\nHow to: do per-user retrieval\\n\\nExtraction\\u200b\\nExtraction is when you use LLMs to extract structured information from unstructured text.\\nFor a high level tutorial on extraction, check out this guide.\\n\\nHow to: use reference examples\\nHow to: handle long text\\nHow to: do extraction without using function calling\\n\\nChatbots\\u200b\\nChatbots involve using an LLM to have a conversation.\\nFor a high-level tutorial on building chatbots, check out this guide.\\n\\nHow to: manage memory\\nHow to: do retrieval\\nHow to: use tools\\nHow to: manage large chat history\\n\\nQuery analysis\\u200b\\nQuery Analysis is the task of using an LLM to generate a query to send to a retriever.\\nFor a high-level tutorial on query analysis, check out this guide.\\n\\nHow to: add examples to the prompt\\nHow to: handle cases where no queries are generated\\nHow to: handle multiple queries\\nHow to: handle multiple retrievers\\nHow to: construct filters\\nHow to: deal with high cardinality categorical variables\\n\\nQ&A over SQL + CSV\\u200b\\nYou can use LLMs to do question answering over tabular data.\\nFor a high-level tutorial, check out this guide.\\n\\nHow to: use prompting to improve results\\nHow to: do query validation\\nHow to: deal with large databases\\nHow to: deal with CSV files\\n\\nQ&A over graph databases\\u200b\\nYou can use an LLM to do question answering over graph databases.\\nFor a high-level tutorial, check out this guide.\\n\\nHow to: add a semantic layer over the database\\nHow to: construct knowledge graphs\\n\\nSummarization\\u200b\\nLLMs can summarize and otherwise distill desired information from text, including\\nlarge volumes of text. For a high-level tutorial, check out this guide.\\n\\nHow to: summarize text in a single LLM call\\nHow to: summarize text through parallelization\\nHow to: summarize text through iterative refinement\\n\\nLangChain Expression Language (LCEL)\\u200b\\nShould I use LCEL?LCEL is an orchestration solution. See our\\nconcepts page for recommendations on when to\\nuse LCEL.\\nLangChain Expression Language is a way to create arbitrary custom chains. It is built on the Runnable protocol.\\nLCEL cheatsheet: For a quick overview of how to use the main LCEL primitives.\\nMigration guide: For migrating legacy chain abstractions to LCEL.\\n\\nHow to: chain runnables\\nHow to: stream runnables\\nHow to: invoke runnables in parallel\\nHow to: add default invocation args to runnables\\nHow to: turn any function into a runnable\\nHow to: pass through inputs from one chain step to the next\\nHow to: configure runnable behavior at runtime\\nHow to: add message history (memory) to a chain\\nHow to: route between sub-chains\\nHow to: create a dynamic (self-constructing) chain\\nHow to: inspect runnables\\nHow to: add fallbacks to a runnable\\nHow to: pass runtime secrets to a runnable\\n\\nLangGraph\\u200b\\nLangGraph is an extension of LangChain aimed at\\nbuilding robust and stateful multi-actor applications with LLMs by modeling steps as edges and nodes in a graph.\\nLangGraph documentation is currently hosted on a separate site.\\nYou can peruse LangGraph how-to guides here.\\nLangSmith\\u200b\\nLangSmith allows you to closely trace, monitor and evaluate your LLM application.\\nIt seamlessly integrates with LangChain and LangGraph, and you can use it to inspect and debug individual steps of your chains and agents as you build.\\nLangSmith documentation is hosted on a separate site.\\nYou can peruse LangSmith how-to guides here, but we\\'ll highlight a few sections that are particularly\\nrelevant to LangChain below:\\nEvaluation\\u200b\\n\\nEvaluating performance is a vital part of building LLM-powered applications.\\nLangSmith helps with every step of the process from creating a dataset to defining metrics to running evaluators.\\nTo learn more, check out the LangSmith evaluation how-to guides.\\nTracing\\u200b\\n\\nTracing gives you observability inside your chains and agents, and is vital in diagnosing issues.\\n\\nHow to: trace with LangChain\\nHow to: add metadata and tags to traces\\n\\nYou can see general tracing-related how-tos in this section of the LangSmith docs.Edit this pagePreviousSummarize TextNextHow-to guidesInstallationKey featuresComponentsChat modelsMessagesPrompt templatesExample selectorsLLMsOutput parsersDocument loadersText splittersEmbedding modelsVector storesRetrieversIndexingToolsMultimodalAgentsCallbacksCustomSerializationUse casesQ&A with RAGExtractionChatbotsQuery analysisQ&A over SQL + CSVQ&A over graph databasesSummarizationLangChain Expression Language (LCEL)LangGraphLangSmithEvaluationTracingCommunityLangChain ForumTwitterSlackGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright © 2025 LangChain, Inc.\\n\\n', name='retriver_tool_langgrah_blog', id='b2bcc66f-69b5-41a1-a672-dece844cd4a6', tool_call_id='call_q5JBr6uvZrXJotf8C3AJuyf1'),\n",
       "  ToolMessage(content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGuides\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\n            \\n            \\nOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!\\n\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              Guides\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Get started\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Additional resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Guides\\n          \\n\\n\\n\\n\\n\\n    Agent development\\n    \\n  \\n\\n\\n\\n\\n\\n            Agent development\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n    Run an agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph APIs\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph APIs\\n          \\n\\n\\n\\n\\n    Graph API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Functional API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Runtime\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Core capabilities\\n    \\n  \\n\\n\\n\\n\\n\\n            Core capabilities\\n          \\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Persistence\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Durable execution\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Context\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Models\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Subgraphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    MCP\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tracing\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Platform-only capabilities\\n    \\n  \\n\\n\\n\\n\\n\\n            Platform-only capabilities\\n          \\n\\n\\n\\n\\n    LangGraph Platform\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Authentication & access control\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Assistants\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Double-texting\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Webhooks\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Cron jobs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Server customization\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Data management\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Additional resources\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Agent development\\n    \\n\\n\\n\\n\\n\\n      LangGraph APIs\\n    \\n\\n\\n\\n\\n\\n      Core capabilities\\n    \\n\\n\\n\\n\\n\\n      Platform-only capabilities\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGuides¶\\nThe pages in this section provide a conceptual overview and how-tos for the following topics:\\nAgent development¶\\n\\nOverview: Use prebuilt components to build an agent.\\nRun an agent: Run an agent by providing input, interpreting output, enabling streaming, and controlling execution limits.\\n\\nLangGraph APIs¶\\n\\nGraph API: Use the Graph API to define workflows using a graph paradigm.\\nFunctional API: Use Functional API to build workflows using a functional paradigm without thinking about the graph structure.\\nRuntime: Pregel implements LangGraph\\'s runtime, managing the execution of LangGraph applications.\\n\\nCore capabilities¶\\nThese capabilities are available in both LangGraph OSS and the LangGraph Platform.\\n\\nStreaming: Stream outputs from a LangGraph graph.\\nPersistence: Persist the state of a LangGraph graph.\\nDurable execution: Save progress at key points in the graph execution.\\nMemory: Remember information about previous interactions.\\nContext: Pass outside data to a LangGraph graph to provide context for the graph execution.\\nModels: Integrate various LLMs into your LangGraph application.\\nTools: Interface directly with external systems.\\nHuman-in-the-loop: Pause a graph and wait for human input at any point in a workflow.\\nTime travel: Travel back in time to a specific point in the execution of a LangGraph graph.\\nSubgraphs: Build modular graphs.\\nMulti-agent: Break down a complex workflow into multiple agents.\\nMCP: Use MCP servers in a LangGraph graph.\\nEvaluation: Use LangSmith to evaluate your graph\\'s performance.\\n\\nPlatform-only capabilities¶\\nThese capabilities are only available in LangGraph Platform.\\n\\nAuthentication and access control: Authenticate and authorize users to access a LangGraph graph.\\nAssistants: Build assistants that can be used to interact with a LangGraph graph.\\nDouble-texting: Handle double-texting (consecutive messages before a first response is returned) in a LangGraph graph.\\nWebhooks: Send webhooks to a LangGraph graph.\\nCron jobs: Schedule jobs to run at a specific time.\\nServer customization: Customize the server that runs a LangGraph graph.\\nData management: Manage data in a LangGraph graph.\\nDeployment: Deploy a LangGraph graph to a server.\\n\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                Agent architectures\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                Overview\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Copyright © 2025 LangChain, Inc | Consent Preferences\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\n            \\n            \\nOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!\\n\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              Overview\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Get started\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Additional resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Guides\\n          \\n\\n\\n\\n\\n\\n    Agent development\\n    \\n  \\n\\n\\n\\n\\n\\n            Agent development\\n          \\n\\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      What is an agent?\\n    \\n\\n\\n\\n\\n\\n      Key features\\n    \\n\\n\\n\\n\\n\\n      High-level building blocks\\n    \\n\\n\\n\\n\\n\\n      Package ecosystem\\n    \\n\\n\\n\\n\\n\\n      Visualize an agent graph\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n    Run an agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph APIs\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph APIs\\n          \\n\\n\\n\\n\\n    Graph API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Functional API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Runtime\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Core capabilities\\n    \\n  \\n\\n\\n\\n\\n\\n            Core capabilities\\n          \\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Persistence\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Durable execution\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Context\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Models\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Subgraphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    MCP\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tracing\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Platform-only capabilities\\n    \\n  \\n\\n\\n\\n\\n\\n            Platform-only capabilities\\n          \\n\\n\\n\\n\\n    LangGraph Platform\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Authentication & access control\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Assistants\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Double-texting\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Webhooks\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Cron jobs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Server customization\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Data management\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Additional resources\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      What is an agent?\\n    \\n\\n\\n\\n\\n\\n      Key features\\n    \\n\\n\\n\\n\\n\\n      High-level building blocks\\n    \\n\\n\\n\\n\\n\\n      Package ecosystem\\n    \\n\\n\\n\\n\\n\\n      Visualize an agent graph\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nagent\\n\\n\\n\\n\\nAgent development using prebuilt components¶\\nLangGraph provides both low-level primitives and high-level prebuilt components for building agent-based applications. This section focuses on the prebuilt, ready-to-use components designed to help you construct agentic systems quickly and reliably—without the need to implement orchestration, memory, or human feedback handling from scratch.\\nWhat is an agent?¶\\nAn agent consists of three components: a large language model (LLM), a set of tools it can use, and a prompt that provides instructions.\\nThe LLM operates in a loop. In each iteration, it selects a tool to invoke, provides input, receives the result (an observation), and uses that observation to inform the next action. The loop continues until a stopping condition is met — typically when the agent has gathered enough information to respond to the user.\\n\\n\\nAgent loop: the LLM selects tools and uses their outputs to fulfill a user request.\\n\\nKey features¶\\nLangGraph includes several capabilities essential for building robust, production-ready agentic systems:\\n\\nMemory integration: Native support for short-term (session-based) and long-term (persistent across sessions) memory, enabling stateful behaviors in chatbots and assistants.\\nHuman-in-the-loop control: Execution can pause indefinitely to await human feedback—unlike websocket-based solutions limited to real-time interaction. This enables asynchronous approval, correction, or intervention at any point in the workflow.\\nStreaming support: Real-time streaming of agent state, model tokens, tool outputs, or combined streams.\\nDeployment tooling: Includes infrastructure-free deployment tools. LangGraph Platform supports testing, debugging, and deployment.\\nStudio: A visual IDE for inspecting and debugging workflows.\\nSupports multiple deployment options for production.\\n\\n\\n\\nHigh-level building blocks¶\\nLangGraph comes with a set of prebuilt components that implement common agent behaviors and workflows. These abstractions are built on top of the LangGraph framework, offering a faster path to production while remaining flexible for advanced customization.\\nUsing LangGraph for agent development allows you to focus on your application\\'s logic and behavior, instead of building and maintaining the supporting infrastructure for state, memory, and human feedback.\\nPackage ecosystem¶\\nThe high-level components are organized into several packages, each with a specific focus.\\n\\n\\n\\nPackage\\nDescription\\nInstallation\\n\\n\\n\\n\\nlanggraph-prebuilt (part of langgraph)\\nPrebuilt components to create agents\\npip install -U langgraph langchain\\n\\n\\nlanggraph-supervisor\\nTools for building supervisor agents\\npip install -U langgraph-supervisor\\n\\n\\nlanggraph-swarm\\nTools for building a swarm multi-agent system\\npip install -U langgraph-swarm\\n\\n\\nlangchain-mcp-adapters\\nInterfaces to MCP servers for tool and resource integration\\npip install -U langchain-mcp-adapters\\n\\n\\nlangmem\\nAgent memory management: short-term and long-term\\npip install -U langmem\\n\\n\\nagentevals\\nUtilities to evaluate agent performance\\npip install -U agentevals\\n\\n\\n\\nVisualize an agent graph¶\\nUse the following tool to visualize the graph generated by\\ncreate_react_agent\\nand to view an outline of the corresponding code.\\nIt allows you to explore the infrastructure of the agent as defined by the presence of:\\n\\ntools: A list of tools (functions, APIs, or other callable objects) that the agent can use to perform tasks.\\npre_model_hook: A function that is called before the model is invoked. It can be used to condense messages or perform other preprocessing tasks.\\npost_model_hook: A function that is called after the model is invoked. It can be used to implement guardrails, human-in-the-loop flows, or other postprocessing tasks.\\nresponse_format: A data structure used to constrain the type of the final output, e.g., a pydantic BaseModel.\\n\\n\\n\\n\\nFeatures\\n tools\\n pre_model_hook\\n post_model_hook\\n response_format\\n\\n\\n\\nGraph\\n\\n\\n\\nThe following code snippet shows how to create the above agent (and underlying graph) with\\ncreate_react_agent:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                Guides\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                Run an agent\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Copyright © 2025 LangChain, Inc | Consent Preferences\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRun an agent\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Skip to content\\n        \\n\\n\\n\\n\\n\\n\\n\\n            \\n            \\nOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!\\n\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            LangGraph\\n          \\n\\n\\n\\n            \\n              Run an agent\\n            \\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Initializing search\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Get started\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Guides\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Reference\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Examples\\n\\n        \\n\\n\\n\\n          \\n  \\n  \\n    \\n  \\n  Additional resources\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph\\n  \\n\\n\\n\\n\\n\\n\\n    GitHub\\n  \\n\\n\\n\\n\\n\\n\\n    Get started\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n    Guides\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n            Guides\\n          \\n\\n\\n\\n\\n\\n    Agent development\\n    \\n  \\n\\n\\n\\n\\n\\n            Agent development\\n          \\n\\n\\n\\n\\n    Overview\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Run an agent\\n    \\n  \\n\\n\\n\\n\\n    Run an agent\\n    \\n  \\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Basic usage\\n    \\n\\n\\n\\n\\n\\n      Inputs and outputs\\n    \\n\\n\\n\\n\\n\\n      Input format\\n    \\n\\n\\n\\n\\n\\n      Output format\\n    \\n\\n\\n\\n\\n\\n      Streaming output\\n    \\n\\n\\n\\n\\n\\n      Max iterations\\n    \\n\\n\\n\\n\\n\\n      Additional Resources\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    LangGraph APIs\\n    \\n  \\n\\n\\n\\n\\n\\n            LangGraph APIs\\n          \\n\\n\\n\\n\\n    Graph API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Functional API\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Runtime\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Core capabilities\\n    \\n  \\n\\n\\n\\n\\n\\n            Core capabilities\\n          \\n\\n\\n\\n\\n    Streaming\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Persistence\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Durable execution\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Memory\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Context\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Models\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tools\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Human-in-the-loop\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Time travel\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Subgraphs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Multi-agent\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    MCP\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Tracing\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Platform-only capabilities\\n    \\n  \\n\\n\\n\\n\\n\\n            Platform-only capabilities\\n          \\n\\n\\n\\n\\n    LangGraph Platform\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Authentication & access control\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Assistants\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Double-texting\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Webhooks\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Cron jobs\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Server customization\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Data management\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Deployment\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Reference\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Examples\\n    \\n  \\n\\n\\n\\n\\n\\n\\n    Additional resources\\n    \\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Table of contents\\n    \\n\\n\\n\\n\\n      Basic usage\\n    \\n\\n\\n\\n\\n\\n      Inputs and outputs\\n    \\n\\n\\n\\n\\n\\n      Input format\\n    \\n\\n\\n\\n\\n\\n      Output format\\n    \\n\\n\\n\\n\\n\\n      Streaming output\\n    \\n\\n\\n\\n\\n\\n      Max iterations\\n    \\n\\n\\n\\n\\n\\n      Additional Resources\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nagent\\n\\n\\n\\n\\nRunning agents¶\\nAgents support both synchronous and asynchronous execution using either .invoke() / await .ainvoke() for full responses, or .stream() / .astream() for incremental streaming output. This section explains how to provide input, interpret output, enable streaming, and control execution limits.\\nBasic usage¶\\nAgents can be executed in two primary modes:\\n\\nSynchronous using .invoke() or .stream()\\nAsynchronous using await .ainvoke() or async for with .astream()\\n\\nSync invocationAsync invocation\\n\\n\\nfrom langgraph.prebuilt import create_react_agent\\n\\nagent = create_react_agent(...)\\n\\nresponse = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]})\\n\\n\\n\\nfrom langgraph.prebuilt import create_react_agent\\n\\nagent = create_react_agent(...)\\nresponse = await agent.ainvoke({\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]})\\n\\n\\n\\n\\nInputs and outputs¶\\nAgents use a language model that expects a list of messages as an input. Therefore, agent inputs and outputs are stored as a list of messages under the messages key in the agent state.\\nInput format¶\\nAgent input must be a dictionary with a messages key. Supported formats are:\\n\\n\\n\\nFormat\\nExample\\n\\n\\n\\n\\nString\\n{\"messages\": \"Hello\"}  — Interpreted as a HumanMessage\\n\\n\\nMessage dictionary\\n{\"messages\": {\"role\": \"user\", \"content\": \"Hello\"}}\\n\\n\\nList of messages\\n{\"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}]}\\n\\n\\nWith custom state\\n{\"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}], \"user_name\": \"Alice\"} — If using a custom state_schema\\n\\n\\n\\nMessages are automatically converted into LangChain\\'s internal message format. You can read\\nmore about LangChain messages in the LangChain documentation.\\n\\nUsing custom agent state\\nYou can provide additional fields defined in your agent’s state schema directly in the input dictionary. This allows dynamic behavior based on runtime data or prior tool outputs.\\nSee the context guide for full details.\\n\\n\\nNote\\nA string input for messages is converted to a HumanMessage. This behavior differs from the prompt parameter in create_react_agent, which is interpreted as a SystemMessage when passed as a string.\\n\\nOutput format¶\\nAgent output is a dictionary containing:\\n\\nmessages: A list of all messages exchanged during execution (user input, assistant replies, tool invocations).\\nOptionally, structured_response if structured output is configured.\\nIf using a custom state_schema, additional keys corresponding to your defined fields may also be present in the output. These can hold updated state values from tool execution or prompt logic.\\n\\nSee the context guide for more details on working with custom state schemas and accessing context.\\nStreaming output¶\\nAgents support streaming responses for more responsive applications. This includes:\\n\\nProgress updates after each step\\nLLM tokens as they\\'re generated\\nCustom tool messages during execution\\n\\nStreaming is available in both sync and async modes:\\nSync streamingAsync streaming\\n\\n\\nfor chunk in agent.stream(\\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]},\\n    stream_mode=\"updates\"\\n):\\n    print(chunk)\\n\\n\\n\\nasync for chunk in agent.astream(\\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]},\\n    stream_mode=\"updates\"\\n):\\n    print(chunk)\\n\\n\\n\\n\\n\\nTip\\nFor full details, see the streaming guide.\\n\\nMax iterations¶\\nTo control agent execution and avoid infinite loops, set a recursion limit. This defines the maximum number of steps the agent can take before raising a GraphRecursionError. You can configure recursion_limit at runtime or when defining agent via .with_config():\\nRuntime.with_config()\\n\\n\\nfrom langgraph.errors import GraphRecursionError\\nfrom langgraph.prebuilt import create_react_agent\\n\\nmax_iterations = 3\\nrecursion_limit = 2 * max_iterations + 1\\nagent = create_react_agent(\\n    model=\"anthropic:claude-3-5-haiku-latest\",\\n    tools=[get_weather]\\n)\\n\\ntry:\\n    response = agent.invoke(\\n        {\"messages\": [{\"role\": \"user\", \"content\": \"what\\'s the weather in sf\"}]},\\n        {\"recursion_limit\": recursion_limit},\\n    )\\nexcept GraphRecursionError:\\n    print(\"Agent stopped due to max iterations.\")\\n\\n\\n\\nfrom langgraph.errors import GraphRecursionError\\nfrom langgraph.prebuilt import create_react_agent\\n\\nmax_iterations = 3\\nrecursion_limit = 2 * max_iterations + 1\\nagent = create_react_agent(\\n    model=\"anthropic:claude-3-5-haiku-latest\",\\n    tools=[get_weather]\\n)\\nagent_with_recursion_limit = agent.with_config(recursion_limit=recursion_limit)\\n\\ntry:\\n    response = agent_with_recursion_limit.invoke(\\n        {\"messages\": [{\"role\": \"user\", \"content\": \"what\\'s the weather in sf\"}]},\\n    )\\nexcept GraphRecursionError:\\n    print(\"Agent stopped due to max iterations.\")\\n\\n\\n\\n\\nAdditional Resources¶\\n\\nAsync programming in LangChain\\n\\n\\n\\n\\n\\n\\n\\n\\n  Back to top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Previous\\n              \\n\\n                Overview\\n              \\n\\n\\n\\n\\n\\n                Next\\n              \\n\\n                Overview\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Copyright © 2025 LangChain, Inc | Consent Preferences\\n\\n  \\n  \\n    Made with\\n    \\n      Material for MkDocs\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', name='retriver_vector_langgraph_blog', id='9e68d967-0611-44db-9c79-8ce4ec3798cb', tool_call_id='call_tFJ5eThYE5hYJpN2dUPypIgZ'),\n",
       "  HumanMessage(content='Langgraph is a framework within the LangChain ecosystem designed for building agent-based applications. It provides tools for constructing agent workflows using either a graph or functional API and includes features like streaming, memory management, and human-in-the-loop capabilities. Langgraph also supports agent development with various high-level prebuilt components focused on rapid production deployment.', additional_kwargs={}, response_metadata={}, id='8edcbc92-9ddf-4a81-95b6-afdab895a2bc')]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\":\"What is Langgraph?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ac0ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
